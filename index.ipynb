{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(boston['target'], columns = ['target'])\n",
    "X = pd.DataFrame(boston['data'], columns = boston['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X.columns)\n",
    "\n",
    "all_data = pd.concat([y, X_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target      CRIM        ZN     INDUS      CHAS       NOX        RM  \\\n",
       "0    24.0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672   \n",
       "1    21.6 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274   \n",
       "2    34.7 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714   \n",
       "3    33.4 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303   \n",
       "4    36.2 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577   \n",
       "\n",
       "        AGE       DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0 -0.120013  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.367166  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2 -0.265812  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3 -0.809889  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4 -0.511180  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_scaled, y, cv = crossvalidation, n_jobs=-1))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combinations = list(combinations(X.columns, 2))\n",
    "\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combinations:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring = 'r2', cv = crossvalidation, n_jobs = -1))\n",
    "    if score > baseline:\n",
    "        interactions.append((comb[0], comb[1], round(score, 3)))\n",
    "        \n",
    "print('Top 7 interactions:', sorted(interactions, key = lambda inter: inter[2], reverse = True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_inter = X_scaled.copy()\n",
    "for interaction in interactions:\n",
    "    df_inter[interaction[0] + '_' + interaction[1]] = df_inter[interaction[0]] * df_inter[interaction[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>...</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>AGE_DIS</th>\n",
       "      <th>AGE_TAX</th>\n",
       "      <th>AGE_PTRATIO</th>\n",
       "      <th>AGE_B</th>\n",
       "      <th>DIS_RAD</th>\n",
       "      <th>DIS_TAX</th>\n",
       "      <th>DIS_PTRATIO</th>\n",
       "      <th>TAX_PTRATIO</th>\n",
       "      <th>B_LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.016828</td>\n",
       "      <td>0.080002</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>-0.137808</td>\n",
       "      <td>-0.093468</td>\n",
       "      <td>-0.204572</td>\n",
       "      <td>0.972582</td>\n",
       "      <td>-0.474379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>0.204570</td>\n",
       "      <td>-0.362514</td>\n",
       "      <td>-0.111286</td>\n",
       "      <td>0.161939</td>\n",
       "      <td>-0.483549</td>\n",
       "      <td>-0.550100</td>\n",
       "      <td>-0.168872</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>-0.217191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-0.148100</td>\n",
       "      <td>0.262444</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>-0.105375</td>\n",
       "      <td>-0.483549</td>\n",
       "      <td>-0.550100</td>\n",
       "      <td>-0.168872</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>-0.479172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-0.872847</td>\n",
       "      <td>0.895830</td>\n",
       "      <td>-0.091543</td>\n",
       "      <td>-0.337046</td>\n",
       "      <td>-0.811452</td>\n",
       "      <td>-1.192101</td>\n",
       "      <td>0.121819</td>\n",
       "      <td>-0.125027</td>\n",
       "      <td>-0.566613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-0.550917</td>\n",
       "      <td>0.565424</td>\n",
       "      <td>-0.057780</td>\n",
       "      <td>-0.225457</td>\n",
       "      <td>-0.811452</td>\n",
       "      <td>-1.192101</td>\n",
       "      <td>0.121819</td>\n",
       "      <td>-0.125027</td>\n",
       "      <td>-0.452740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX  ...  RM_LSTAT   AGE_DIS   AGE_TAX  \\\n",
       "0  0.140214 -0.982843 -0.666608  ... -0.444930 -0.016828  0.080002   \n",
       "1  0.557160 -0.867883 -0.987329  ... -0.095668  0.204570 -0.362514   \n",
       "2  0.557160 -0.867883 -0.987329  ... -1.550451 -0.148100  0.262444   \n",
       "3  1.077737 -0.752922 -1.106115  ... -1.383713 -0.872847  0.895830   \n",
       "4  1.077737 -0.752922 -1.106115  ... -1.261136 -0.550917  0.565424   \n",
       "\n",
       "   AGE_PTRATIO     AGE_B   DIS_RAD   DIS_TAX  DIS_PTRATIO  TAX_PTRATIO  \\\n",
       "0     0.175100 -0.052932 -0.137808 -0.093468    -0.204572     0.972582   \n",
       "1    -0.111286  0.161939 -0.483549 -0.550100    -0.168872     0.299254   \n",
       "2     0.080566 -0.105375 -0.483549 -0.550100    -0.168872     0.299254   \n",
       "3    -0.091543 -0.337046 -0.811452 -1.192101     0.121819    -0.125027   \n",
       "4    -0.057780 -0.225457 -0.811452 -1.192101     0.121819    -0.125027   \n",
       "\n",
       "    B_LSTAT  \n",
       "0 -0.474379  \n",
       "1 -0.217191  \n",
       "2 -0.479172  \n",
       "3 -0.566613  \n",
       "4 -0.452740  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in X.columns:\n",
    "    for degree in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X_transformed = poly.fit_transform(X[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X_transformed)], axis=1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score, 3)))\n",
    "print('Top 10 polynomials: %s' %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "CHAS       0.718\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.720\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(X_transformed, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>TAX_PTRATIO</th>\n",
       "      <th>B_LSTAT</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972582</td>\n",
       "      <td>-0.474379</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>-0.217191</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>-0.479172</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125027</td>\n",
       "      <td>-0.566613</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125027</td>\n",
       "      <td>-0.452740</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...  TAX_PTRATIO   B_LSTAT     RM       RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ...     0.972582 -0.474379  6.575  43.230625   \n",
       "1 -0.867883 -0.987329 -0.303094  ...     0.299254 -0.217191  6.421  41.229241   \n",
       "2 -0.867883 -0.987329 -0.303094  ...     0.299254 -0.479172  7.185  51.624225   \n",
       "3 -0.752922 -1.106115  0.113032  ...    -0.125027 -0.566613  6.998  48.972004   \n",
       "4 -0.752922 -1.106115  0.113032  ...    -0.125027 -0.452740  7.147  51.079609   \n",
       "\n",
       "         RM_3         RM_4  LSTAT  LSTAT_2     LSTAT_3      LSTAT_4  \n",
       "0  284.241359  1868.886938   4.98  24.8004  123.505992   615.059840  \n",
       "1  264.732956  1699.850313   9.14  83.5396  763.551944  6978.864768  \n",
       "2  370.920057  2665.060607   4.03  16.2409   65.450827   263.766833  \n",
       "3  342.706084  2398.257176   2.94   8.6436   25.412184    74.711821  \n",
       "4  365.065966  2609.126456   5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957159933588722"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "full_model = np.mean(cross_val_score(regression, df_inter, y, scoring='r2', cv=crossvalidation))\n",
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7168057552393374\n",
      "Test r^2: 0.7789410172622857\n",
      "Training MSE: 22.477983821877896\n",
      "Test MSE: 21.897765396049497\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Test r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8588443668126422\n",
      "Test r^2: 0.8805365025398559\n",
      "Training MSE: 11.203949578261678\n",
      "Test MSE: 11.8338717041761\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8441981445614429\n",
      "Test r^2: 0.8795677349585465\n",
      "Training MSE: 12.366464540711982\n",
      "Test MSE: 11.929836342012067\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
